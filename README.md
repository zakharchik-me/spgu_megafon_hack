# spgu_megafon_hack

### На этапе раннего анализа:

Данные были грязные и разряженные, одиноки

Начнем с раннего анализа данных - на этом этапе мы в общих чертах смотрели на данные, занимались 

●	Объединением, устранение аномалий, дубликатов, явная типизация, группировки (устроняли выбросы фильтр Хэмлея по оценке медиана окна , что в будущем улучшило метрики качества)

●	визуализацией данных
Графики представлены

![image](https://user-images.githubusercontent.com/72201760/234550647-b8a04075-2693-4e0a-82aa-65a7f4f5f505.png)

### На этапе Серьезной Аналитики:

●	Построили ряды описывающие среднее использование связи и интернета в городах на каждый месяц

●	добавили на ряды праздники

●	смотрели корреляции признаковых пространств

●	искали сезонность, тендинци. - ее не было тестом фуллера проверяли стационарность то есть нашли тренд

●	интерполировали разреженный временной ряд линейной регрессией (что позволило уменьшить квадратичное отклонение полученных значений от реальных - которые были неизвестны)


![image](https://user-images.githubusercontent.com/72201760/234550761-6ebad500-637e-4c3b-89cd-6a3dabf5434b.png)

### Про этап притягивания сторонних данных:

Путем следования логики аб тестирования на тестовом множестве прошлого, если метрики качества улучшались применяли, нет отвергали гипотезу

●1. Из множества проверенных гипотез притягивания, я перечислю только принятые тк множества городов из разных частей страны - использовали доходы граждан по регионам - доп. фича ( ⇒ улучшение метрик качества модели)

● 2.использовали карту расстояний, исходя из логики, (вряд ли жители условного Владивостока часто ездят отдыхать в Сочи) тоже доп. фича тоже улучшение метрик качества

●генерирования синтаксических данных из количества туристов и доли мегафона на регион, и последующее заполнение недостающих данных мультипростравнственным метод ближайших соседей, где таргет - возраст и город из и в который

![image](https://user-images.githubusercontent.com/72201760/234550827-582e7989-2579-4086-b5bf-2c503986c701.png)

### Про решение:
Краткое решение без подробностей
●У нас аж 3ая точность, что первое - полезно бизнес заказчику, можно выудить данные на полгода, год и два. Так же при контрольных таковых точках, точность увеличивается
●И у нас Ансамбль из интегрированная модель авторегрессии — скользящего среднего с сезонностью
и нейросеть трансформенной архитектуры. Этот ансамбль основан на методе степ бай вектор предсказии где тфт использует показния статистической модели

![image](https://user-images.githubusercontent.com/72201760/234552015-fd3d41ee-b850-467d-bde7-9f807fd28cf3.png)

### Почему трансформер,
Gочему не взять степ бай степ легкие

Дело в том, что разряженный на 95% ряды дают переобучения всех легких и средних моделей,

К тому же степ бай степ предсказания копит в себе ошибку с увеличением окна, что на 2ух годах нерелевантно задаче.

Проверяли, к примеру, гипотезу и запускали изначально лстм, который работает с длинными последовательностями,

но такая разряженность, искажает и переобучает да же рекурентрную нейронную сеть с механизмом запоминания последовательностей

